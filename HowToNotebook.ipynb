{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How-To Notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use the repository."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line of code below contains all of the relevant parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStop = 20\n",
    "batch_size = 8\n",
    "epochs = 1\n",
    "hierarchyLevel = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to open dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets are opened with the corresponding class. The class has all the necessary preprocessing steps built-in. The main output of the data class are the dataloaders. These can be passed to the BSC model later for training, validation and testing. Below the difference between the pandas dataframes shows the data preprocessing in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>published</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The New York Times Daily Crossword Puzzles: Th...</td>\n",
       "      <td>Monday’s Crosswords Do with EaseTuesday’s Cros...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Dec 28, 1996</td>\n",
       "      <td>[Nonfiction, Games]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Creatures of the Night (Second Edition)</td>\n",
       "      <td>Two of literary comics modern masters present ...</td>\n",
       "      <td>Neil Gaiman</td>\n",
       "      <td>Nov 29, 2016</td>\n",
       "      <td>[Fiction, Graphic Novels &amp; Manga]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cornelia and the Audacious Escapades of the So...</td>\n",
       "      <td>Eleven-year-old Cornelia is the daughter of tw...</td>\n",
       "      <td>Lesley M. M. Blume</td>\n",
       "      <td>Jan 08, 2008</td>\n",
       "      <td>[Children’s Books, Children’s Middle Grade Books]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Alchemist's Daughter</td>\n",
       "      <td>During the English Age of Reason, a woman cloi...</td>\n",
       "      <td>Katharine McMahon</td>\n",
       "      <td>Oct 24, 2006</td>\n",
       "      <td>[Fiction, Historical Fiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dangerous Boy</td>\n",
       "      <td>A modern-day retelling of The Strange Case of ...</td>\n",
       "      <td>Mandy Hubbard</td>\n",
       "      <td>Aug 30, 2012</td>\n",
       "      <td>[Teen &amp; Young Adult, Teen &amp; Young Adult Myster...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  The New York Times Daily Crossword Puzzles: Th...   \n",
       "1            Creatures of the Night (Second Edition)   \n",
       "2  Cornelia and the Audacious Escapades of the So...   \n",
       "3                           The Alchemist's Daughter   \n",
       "4                                      Dangerous Boy   \n",
       "\n",
       "                                                body              author  \\\n",
       "0  Monday’s Crosswords Do with EaseTuesday’s Cros...      New York Times   \n",
       "1  Two of literary comics modern masters present ...         Neil Gaiman   \n",
       "2  Eleven-year-old Cornelia is the daughter of tw...  Lesley M. M. Blume   \n",
       "3  During the English Age of Reason, a woman cloi...   Katharine McMahon   \n",
       "4  A modern-day retelling of The Strange Case of ...       Mandy Hubbard   \n",
       "\n",
       "       published                                             topics  \n",
       "0  Dec 28, 1996                                 [Nonfiction, Games]  \n",
       "1  Nov 29, 2016                   [Fiction, Graphic Novels & Manga]  \n",
       "2  Jan 08, 2008   [Children’s Books, Children’s Middle Grade Books]  \n",
       "3  Oct 24, 2006                       [Fiction, Historical Fiction]  \n",
       "4  Aug 30, 2012   [Teen & Young Adult, Teen & Young Adult Myster...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization:   0%|          | 0/20 [00:00<?, ?it/s]c:\\Users\\luc.stebens\\Anaconda3\\envs\\BERTTextClassification\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Tokenization: 100%|██████████| 20/20 [00:08<00:00,  2.42it/s]\n",
      "Tokenization:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\luc.stebens\\Anaconda3\\envs\\BERTTextClassification\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Tokenization: 100%|██████████| 10/10 [00:04<00:00,  2.32it/s]\n",
      "Tokenization:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\luc.stebens\\Anaconda3\\envs\\BERTTextClassification\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Tokenization: 100%|██████████| 10/10 [00:02<00:00,  4.50it/s]\n",
      "c:\\Code\\BertSentenceClassification\\utils\\utils.py:43: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  torch.tensor(df[\"labels\"][:nbrExamples])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>published</th>\n",
       "      <th>topics</th>\n",
       "      <th>labels</th>\n",
       "      <th>tokenizedTopics</th>\n",
       "      <th>attentionMask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The New York Times Daily Crossword Puzzles: Th...</td>\n",
       "      <td>Monday’s Crosswords Do with EaseTuesday’s Cros...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Dec 28, 1996</td>\n",
       "      <td>[Nonfiction, Games]</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[101, 6928, 1521, 1055, 2892, 22104, 2079, 200...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Creatures of the Night (Second Edition)</td>\n",
       "      <td>Two of literary comics modern masters present ...</td>\n",
       "      <td>Neil Gaiman</td>\n",
       "      <td>Nov 29, 2016</td>\n",
       "      <td>[Fiction, Graphic Novels &amp; Manga]</td>\n",
       "      <td>[2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[101, 2048, 1997, 4706, 5888, 2715, 5972, 2556...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cornelia and the Audacious Escapades of the So...</td>\n",
       "      <td>Eleven-year-old Cornelia is the daughter of tw...</td>\n",
       "      <td>Lesley M. M. Blume</td>\n",
       "      <td>Jan 08, 2008</td>\n",
       "      <td>[Children’s Books, Children’s Middle Grade Books]</td>\n",
       "      <td>[3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[101, 5408, 1011, 2095, 1011, 2214, 9781, 1390...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Alchemist's Daughter</td>\n",
       "      <td>During the English Age of Reason, a woman cloi...</td>\n",
       "      <td>Katharine McMahon</td>\n",
       "      <td>Oct 24, 2006</td>\n",
       "      <td>[Fiction, Historical Fiction]</td>\n",
       "      <td>[2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[101, 2076, 1996, 2394, 2287, 1997, 3114, 1010...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dangerous Boy</td>\n",
       "      <td>A modern-day retelling of The Strange Case of ...</td>\n",
       "      <td>Mandy Hubbard</td>\n",
       "      <td>Aug 30, 2012</td>\n",
       "      <td>[Teen &amp; Young Adult, Teen &amp; Young Adult Myster...</td>\n",
       "      <td>[4, 5, 1, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[101, 1037, 2715, 1011, 2154, 2128, 23567, 207...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  The New York Times Daily Crossword Puzzles: Th...   \n",
       "1            Creatures of the Night (Second Edition)   \n",
       "2  Cornelia and the Audacious Escapades of the So...   \n",
       "3                           The Alchemist's Daughter   \n",
       "4                                      Dangerous Boy   \n",
       "\n",
       "                                                body              author  \\\n",
       "0  Monday’s Crosswords Do with EaseTuesday’s Cros...      New York Times   \n",
       "1  Two of literary comics modern masters present ...         Neil Gaiman   \n",
       "2  Eleven-year-old Cornelia is the daughter of tw...  Lesley M. M. Blume   \n",
       "3  During the English Age of Reason, a woman cloi...   Katharine McMahon   \n",
       "4  A modern-day retelling of The Strange Case of ...       Mandy Hubbard   \n",
       "\n",
       "       published                                             topics  \\\n",
       "0  Dec 28, 1996                                 [Nonfiction, Games]   \n",
       "1  Nov 29, 2016                   [Fiction, Graphic Novels & Manga]   \n",
       "2  Jan 08, 2008   [Children’s Books, Children’s Middle Grade Books]   \n",
       "3  Oct 24, 2006                       [Fiction, Historical Fiction]   \n",
       "4  Aug 30, 2012   [Teen & Young Adult, Teen & Young Adult Myster...   \n",
       "\n",
       "                              labels  \\\n",
       "0  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1  [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2  [3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3  [2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4  [4, 5, 1, 1, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                     tokenizedTopics  \\\n",
       "0  [101, 6928, 1521, 1055, 2892, 22104, 2079, 200...   \n",
       "1  [101, 2048, 1997, 4706, 5888, 2715, 5972, 2556...   \n",
       "2  [101, 5408, 1011, 2095, 1011, 2214, 9781, 1390...   \n",
       "3  [101, 2076, 1996, 2394, 2287, 1997, 3114, 1010...   \n",
       "4  [101, 1037, 2715, 1011, 2154, 2128, 23567, 207...   \n",
       "\n",
       "                                       attentionMask  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from BlurbDataset.BlurbDataset import BlurbDataset\n",
    "data = BlurbDataset(earlyStop=earlyStop, batch_size=batch_size)\n",
    "display(data.trainDF.head())\n",
    "data.prepareData()\n",
    "data.trainDF.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the perprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.saveData()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = BlurbDataset(earlyStop=earlyStop, batch_size=batch_size,\n",
    "                          tokenizedDataPath=\"BlurbDataset\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training and inference the datapoints are masked such that at the chosen hierarchyLevel the datapoints that have label 0 - meaning no label at this hierarchy level - are being excluded. The following line of code shows this in action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contant tensor([6, 8, 2, 0, 0, 3, 5, 2], dtype=torch.int32) and shape of b_labels: torch.Size([8])\n",
      "contant tensor([[  101,  1037,  3748,  ...,     0,     0,     0],\n",
      "        [  101,  3251,  2009,  ...,     0,     0,     0],\n",
      "        [  101,  1996,  2959,  ...,     0,     0,     0],\n",
      "        [  101,  2023,  8001,  ...,     0,     0,     0],\n",
      "        [  101,  2984, 28352,  ...,     0,     0,     0],\n",
      "        [  101,  1996,  2146,  ...,     0,     0,     0]]) and shape of b_input_ids: torch.Size([6, 512])\n",
      "contant tensor([6, 8, 2, 3, 5, 2], dtype=torch.int32) and shape of b_labels: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "hierarchyLevel = 2\n",
    "for batch in data.dataloaders[\"train\"]:\n",
    "    b_labels = batch[2][:,hierarchyLevel]\n",
    "    print(f\"contant {b_labels} and shape of b_labels: {b_labels.shape}\")\n",
    "    b_input_ids = batch[0][b_labels!=0,:]\n",
    "    print(f\"contant {b_input_ids} and shape of b_input_ids: {b_input_ids.shape}\")\n",
    "    b_labels = b_labels[b_labels!=0]\n",
    "    print(f\"contant {b_labels} and shape of b_labels: {b_labels.shape}\")\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to load the BERT model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BERT model is contained within a custom class called BSC - bert for sentence classification. Code show how to initialize the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\luc.stebens\\Anaconda3\\envs\\BERTTextClassification\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from HierarchicalBERT.BERTSentenceClassification import BSC\n",
    "\n",
    "model = BSC(\n",
    "            dataloaders = data.dataloaders,\n",
    "            epochs=epochs,\n",
    "            listLabelDict = data.listLabelDict,\n",
    "            num_labels=data.num_labels,\n",
    "            hierarchyLevel=hierarchyLevel\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training on batch:   0%|          | 0/2 [00:00<?, ?it/s]c:\\Code\\BertSentenceClassification\\HierarchicalBERT\\BERTSentenceClassification.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "c:\\Code\\BertSentenceClassification\\HierarchicalBERT\\BERTSentenceClassification.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return_dict=True)\n",
      "Training on batch: 3it [01:04, 21.53s/it]                       \n",
      "c:\\Code\\BertSentenceClassification\\HierarchicalBERT\\BERTSentenceClassification.py:261: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 4.22\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.00\n",
      "  Validation Loss: 4.16\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and evaluate the training and validation loss over the epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plotTrainingLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on batch:   0%|          | 0/2 [00:00<?, ?it/s]c:\\Code\\BertSentenceClassification\\HierarchicalBERT\\BERTSentenceClassification.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  b_labels = torch.tensor(b_labels[b_labels!=0],dtype=torch.long).to(self.device)\n",
      "Testing on batch:  50%|█████     | 1/2 [00:04<00:04,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0/2\n",
      "True labels: [17  5  3 39]\n",
      "Predictions: [41 41 78 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing on batch: 100%|██████████| 2/2 [00:06<00:00,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.test()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a couple of predicitons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "body = np.array([\"This wordless collection of strips by renowned artist/designer Rian Hughes reveals the lighter side of our obsession with social rankings.When everyone has a number, everyone knows their place. Lower numbers are better, higher numbers are less important, and that’s just the way it is. But what if that number could change? You might try to buck the system and assert your individuality… or you might end up with a big fat zero.Big questions are explored and unexpected answers found in the first solo comics collection from award-winning designer &amp; illustrator Rian Hughes. His whimsical, witty, and insightful strips will make you both smile and consider. Where do you stand in the pecking order? Is your number up? 2018 Pubwest Design Awards – Gold Winner for Graphic Album, New Material\",\n",
    "    \"There’s hot, and then there’s Delilah Devlin. She’s in a class  by herself.\",\n",
    "    \"A little girl proudly shows off her reading skills as she spends a day out on the town with her mom. Children are sure to be delighted as they read along with the narrator in ths fun, rhyming, easy-to-read story.\",\n",
    "    \"The Screech Owls have come to Salt Lake City for the Peewee Winter Games – with the championship game to be played on the same ice surface where the Canadian men and women won Olympic hockey gold! Nish has plans to run his own competition: the Gross-Out Olympics, featuring everything from taping players to dressing room walls with duct tape to the “Snot Shot” – seeing how far they can fire a jellybean using only their noses. He also has a team contest to see who can figure out the Great Nish Secret and guess what the nuttiest Screech Owl of all has buried at centre ice for good luck. But that secret pales once the Owls find out something strange – something terrifying – is going on in the tunnels deep beneath the magnificent hills surrounding the Olympic site.\",\n",
    "    \"Illus. in full color. Wild and domestic animals that preschoolers will want to see.From the Trade Paperback edition.\",            \n",
    "])\n",
    "datapoints = pd.DataFrame()\n",
    "datapoints[\"body\"] = body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This wordless collection of strips by renowned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There’s hot, and then there’s Delilah Devlin. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A little girl proudly shows off her reading sk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Screech Owls have come to Salt Lake City f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Illus. in full color. Wild and domestic animal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body\n",
       "0  This wordless collection of strips by renowned...\n",
       "1  There’s hot, and then there’s Delilah Devlin. ...\n",
       "2  A little girl proudly shows off her reading sk...\n",
       "3  The Screech Owls have come to Salt Lake City f...\n",
       "4  Illus. in full color. Wild and domestic animal..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization:   0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\luc.stebens\\Anaconda3\\envs\\BERTTextClassification\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Tokenization: 100%|██████████| 5/5 [00:00<00:00,  6.35it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.inference(datapoints, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m translatedPredictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtranslatePredictions(predictions)\n",
      "File \u001b[1;32mc:\\Code\\BertSentenceClassification\\HierarchicalBERT\\BERTSentenceClassification.py:372\u001b[0m, in \u001b[0;36mBSC.translatePredictions\u001b[1;34m(self, predictions)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtranslatePredictions\u001b[39m(\u001b[39mself\u001b[39m, predictions:np\u001b[39m.\u001b[39marray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39marray:\n\u001b[1;32m--> 372\u001b[0m     \u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlistLabelDicts[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhierarchyLevel]\n\u001b[0;32m    373\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([\u001b[39mlist\u001b[39m(\u001b[39mdict\u001b[39m\u001b[39m.\u001b[39mkeys())[\u001b[39mlist\u001b[39m(\u001b[39mdict\u001b[39m\u001b[39m.\u001b[39mvalues())\u001b[39m.\u001b[39mindex(prediction)] \n\u001b[0;32m    374\u001b[0m                      \u001b[39mfor\u001b[39;00m prediction \u001b[39min\u001b[39;00m predictions])\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "translatedPredictions = model.translatePredictions(predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.saveModel(\"testModel\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "from HierarchicalBERT.BERTSentenceClassification import loadBSCmodel\n",
    "model1 = loadBSCmodel(\"testModel\", listLabelDict=data.listLabelDict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare model and model1. If you do the comparison, be careful that the model you are trying to save is being saved under a name that is not being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization:   0%|          | 0/6 [00:00<?, ?it/s]c:\\Users\\luc.stebens\\Anaconda3\\envs\\BERTTextClassification\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Tokenization: 100%|██████████| 6/6 [00:03<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.39166233 -0.01105917  0.62757355  0.2581002  -0.5915158  -0.42328113\n",
      "   0.69254434  0.32350126  0.14881566  0.13325533  0.683328   -0.17779809\n",
      "  -0.09233239 -0.16790654 -0.13353041 -0.24922892  0.4954337   0.17995632\n",
      "   0.1414423  -0.17373946  0.27532426  0.03611121  0.13871895 -0.24745283\n",
      "  -0.44242415 -0.83755773  0.01493363 -0.5309751   0.11680061 -0.09623164\n",
      "   0.20086399 -0.02508073  0.25304705 -0.10976006  0.06803933  0.11388931\n",
      "  -0.8511742  -0.6840383  -0.3696006  -0.22373904  0.25922513 -0.90005916\n",
      "  -0.4516124   0.37639132  0.2970895   0.22256057 -0.5775304  -0.03633775\n",
      "   0.3135993  -0.5804622  -0.35701013 -0.7480397  -0.62862164  0.12727606\n",
      "  -0.45576513 -0.0414384   0.18847606 -0.11329078 -0.08643678  0.12724036\n",
      "   0.12335202 -0.22874287 -0.2991783   0.29896784  0.41772845  0.26217222\n",
      "  -0.38913837 -0.62962383 -0.5040003  -0.27541906 -0.129283   -0.29825008\n",
      "  -0.11595756 -0.3540829   0.0956834  -0.02775306  0.6940205  -0.09227671\n",
      "   0.15689558  0.3107318 ]\n",
      " [-0.14058846  0.23826517  0.4127439   0.19500181 -0.54425263 -0.15525483\n",
      "   0.84162056  0.20974219  0.2968884   0.11382529  0.6100584  -0.25685233\n",
      "   0.07832514 -0.01934533  0.07156423 -0.28291535  0.11772206  0.23008548\n",
      "   0.15107712 -0.23805672  0.22175711  0.35320473  0.21646932 -0.02474125\n",
      "  -0.64201725 -0.68680966  0.24974689 -0.63317734 -0.16911486 -0.03929098\n",
      "   0.06944899 -0.09594528  0.16301566 -0.04465562  0.45098537  0.36420777\n",
      "  -0.6375388  -0.43353707 -0.3948411  -0.18812144  0.23431575 -0.64158183\n",
      "  -0.4553715   0.1781156   0.4562718   0.18832177 -0.6224793   0.02623004\n",
      "   0.39224476 -0.3800481  -0.32013673 -0.67853314 -0.7339156   0.10565864\n",
      "  -0.2723072   0.03302608  0.16401818  0.05853877 -0.171272    0.13102807\n",
      "  -0.06568918 -0.29371762 -0.4153469   0.05311535  0.27453938  0.22733\n",
      "  -0.43423185 -0.37444228 -0.52201605 -0.30708253  0.06435482 -0.37939543\n",
      "  -0.15320379 -0.37644583 -0.236962    0.16498892  0.5387253  -0.06139998\n",
      "  -0.03246497  0.40693432]\n",
      " [-0.38409922 -0.004697    0.58277255  0.24188545 -0.6425295  -0.42941582\n",
      "   0.67375255  0.31350568  0.18691196  0.09768981  0.66901845 -0.22972612\n",
      "  -0.02055287 -0.14715958 -0.09295499 -0.3130335   0.41881293  0.16286069\n",
      "   0.13241065 -0.17423679  0.29178265  0.09876722  0.08583787 -0.22403066\n",
      "  -0.5131343  -0.82588613 -0.00594755 -0.55970716  0.08923867 -0.12048426\n",
      "   0.18582928 -0.02558712  0.22572067 -0.14915182  0.2187574   0.14786753\n",
      "  -0.90193653 -0.672527   -0.40635708 -0.21237361  0.27459815 -0.8074391\n",
      "  -0.4821201   0.33698896  0.3102039   0.25924924 -0.6235506   0.02962914\n",
      "   0.30740672 -0.5591577  -0.36960775 -0.7686396  -0.74931467  0.0110318\n",
      "  -0.44392216 -0.06525464  0.14976874 -0.10781754 -0.07885293  0.0692796\n",
      "   0.08834253 -0.19232765 -0.3341323   0.30773517  0.39073426  0.24717246\n",
      "  -0.44531775 -0.588522   -0.52061874 -0.3192011  -0.11093359 -0.3532616\n",
      "  -0.1826921  -0.4477309   0.00226457  0.0245986   0.6088537  -0.05893867\n",
      "   0.11143074  0.3098105 ]\n",
      " [-0.38798597  0.02564994  0.70919335  0.3107669  -0.64018774 -0.35538852\n",
      "   0.81950307  0.351758    0.15267478  0.15144825  0.6248974  -0.20705463\n",
      "  -0.13038418 -0.12163936 -0.18213516 -0.22855236  0.47673312  0.15177521\n",
      "   0.16598615 -0.1810947   0.2092826   0.13992967  0.0368157  -0.20822707\n",
      "  -0.43088934 -0.8171991   0.03076288 -0.526747    0.08558294 -0.05896622\n",
      "   0.12876192  0.01931494  0.23176596 -0.1503905   0.13668069  0.15954047\n",
      "  -0.8859391  -0.65505886 -0.36574996 -0.28518808  0.15749025 -0.8957467\n",
      "  -0.5370771   0.38740554  0.27868187  0.21466313 -0.5707701   0.07482547\n",
      "   0.19229662 -0.5541581  -0.3502269  -0.7750922  -0.6384995   0.06070729\n",
      "  -0.42537722 -0.04019539  0.1820682  -0.11595744 -0.08057731  0.14717275\n",
      "   0.08096617 -0.3076155  -0.36974913  0.24414062  0.40692234  0.25526085\n",
      "  -0.41867867 -0.5922078  -0.5282996  -0.23421796 -0.08815761 -0.29837847\n",
      "  -0.18156725 -0.4123945   0.04872598 -0.03481311  0.6863576  -0.02754398\n",
      "   0.11813536  0.40124524]\n",
      " [-0.39036712  0.06007484  0.5593312   0.14688641 -0.65263295 -0.5411977\n",
      "   0.574366    0.33015102  0.23486602  0.10670174  0.705386   -0.2827139\n",
      "  -0.14769349 -0.17232913 -0.18993175 -0.23990661  0.48176402  0.25498143\n",
      "   0.07097304 -0.20252785  0.24250326  0.1407946   0.03571743 -0.27031928\n",
      "  -0.42440116 -0.8312377   0.04608586 -0.51835096  0.08336017 -0.14258836\n",
      "   0.18789697 -0.01398838  0.33817756 -0.1585604   0.1748988   0.11731219\n",
      "  -0.8729059  -0.7946071  -0.49163073 -0.2533232   0.2598589  -0.8009248\n",
      "  -0.40212643  0.2424975   0.4407405   0.27786413 -0.56877196  0.02178364\n",
      "   0.38123363 -0.58741474 -0.3769996  -0.83332485 -0.7202083   0.04414653\n",
      "  -0.56447023 -0.15092774  0.16008726 -0.09686132 -0.16890508  0.14063814\n",
      "   0.15907492 -0.05977619 -0.2735783   0.48755747  0.42782903  0.32084304\n",
      "  -0.3346724  -0.69555414 -0.4955463  -0.39330307 -0.04483746 -0.3498962\n",
      "  -0.17460518 -0.4284771   0.12309912  0.07437356  0.58438885 -0.07966954\n",
      "   0.08845697  0.3316505 ]\n",
      " [-0.34625912 -0.00187039  0.6294455   0.2703109  -0.72825783 -0.5318523\n",
      "   0.6931524   0.37428588  0.09938715  0.15029472  0.7294992  -0.17661893\n",
      "  -0.07401168 -0.15970539 -0.21837822 -0.23749559  0.58829075  0.14299135\n",
      "   0.15201268 -0.13651377  0.24405618  0.10997394  0.11735991 -0.25248867\n",
      "  -0.4260165  -0.8894429  -0.06623514 -0.5328641   0.15283114 -0.20286684\n",
      "   0.18859847 -0.06336296  0.35970354 -0.18619247  0.17991412  0.03965234\n",
      "  -0.9473837  -0.8268545  -0.41604224 -0.26832885  0.3298421  -0.9340339\n",
      "  -0.4711648   0.35040054  0.30968726  0.27596062 -0.60482895 -0.00544953\n",
      "   0.32344806 -0.67296803 -0.3543448  -0.893318   -0.7563499   0.05324412\n",
      "  -0.58412564 -0.1430814   0.20461296 -0.12391528 -0.14118336  0.14626329\n",
      "   0.16937464 -0.08462614 -0.22198059  0.46619168  0.40201902  0.30085105\n",
      "  -0.37075612 -0.738641   -0.45401376 -0.23151076 -0.16072088 -0.29261547\n",
      "  -0.13784808 -0.42444912  0.1387258   0.011978    0.7280121  -0.05270352\n",
      "   0.18015122  0.2566182 ]]\n",
      "predictions: [76  6  6  6 10 10]\n",
      "translatedPredictions: ['Travel: Central & South America' 'Cozy Mysteries' 'Cozy Mysteries'\n",
      " 'Cozy Mysteries' 'U.S. History' 'U.S. History']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{model.num_labels}\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "body = np.array([\"This wordless collection of strips by renowned artist/designer Rian Hughes reveals the lighter side of our obsession with social rankings.When everyone has a number, everyone knows their place. Lower numbers are better, higher numbers are less important, and that’s just the way it is. But what if that number could change? You might try to buck the system and assert your individuality… or you might end up with a big fat zero.Big questions are explored and unexpected answers found in the first solo comics collection from award-winning designer &amp; illustrator Rian Hughes. His whimsical, witty, and insightful strips will make you both smile and consider. Where do you stand in the pecking order? Is your number up? 2018 Pubwest Design Awards – Gold Winner for Graphic Album, New Material\",\n",
    "    \"There’s hot, and then there’s Delilah Devlin. She’s in a class  by herself.\",\n",
    "    \"A little girl proudly shows off her reading skills as she spends a day out on the town with her mom. Children are sure to be delighted as they read along with the narrator in ths fun, rhyming, easy-to-read story.\",\n",
    "    \"The Screech Owls have come to Salt Lake City for the Peewee Winter Games – with the championship game to be played on the same ice surface where the Canadian men and women won Olympic hockey gold! Nish has plans to run his own competition: the Gross-Out Olympics, featuring everything from taping players to dressing room walls with duct tape to the “Snot Shot” – seeing how far they can fire a jellybean using only their noses. He also has a team contest to see who can figure out the Great Nish Secret and guess what the nuttiest Screech Owl of all has buried at centre ice for good luck. But that secret pales once the Owls find out something strange – something terrifying – is going on in the tunnels deep beneath the magnificent hills surrounding the Olympic site.\",\n",
    "    \"Illus. in full color. Wild and domestic animals that preschoolers will want to see.From the Trade Paperback edition.\",            \n",
    "    \"With his unique knack for making cutting-edge theoretical science effortlessly accessible, world-renowned physicist Paul Davies now tackles an issue that has boggled minds for centuries: Is time travel possible? The answer, insists Davies, is definitely yes—once you iron out a few kinks in the space-time continuum. With tongue placed firmly in cheek, Davies explains the theoretical physics that make visiting the future and revisiting the past possible, then proceeds to lay out a four-stage process for assembling a time machine and making it work. Wildly inventive and theoretically sound, How to Build a Time Machine is creative science at its best—illuminating, entertaining, and thought provoking.\",\n",
    "])\n",
    "datapoints = pd.DataFrame()\n",
    "datapoints[\"body\"] = body\n",
    "\n",
    "predictions = model.inference(datapoints, batch_size=16)\n",
    "translatedPredictions = model.translatePredictions(predictions)\n",
    "\n",
    "print(f\"predictions: {predictions}\")\n",
    "print(f\"translatedPredictions: {translatedPredictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization:   0%|          | 0/6 [00:00<?, ?it/s]c:\\Users\\luc.stebens\\Anaconda3\\envs\\BERTTextClassification\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Tokenization: 100%|██████████| 6/6 [00:02<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.39166233 -0.01105917  0.62757355  0.2581002  -0.5915158  -0.42328113\n",
      "   0.69254434  0.32350126  0.14881566  0.13325533  0.683328   -0.17779809\n",
      "  -0.09233239 -0.16790654 -0.13353041 -0.24922892  0.4954337   0.17995632\n",
      "   0.1414423  -0.17373946  0.27532426  0.03611121  0.13871895 -0.24745283\n",
      "  -0.44242415 -0.83755773  0.01493363 -0.5309751   0.11680061 -0.09623164\n",
      "   0.20086399 -0.02508073  0.25304705 -0.10976006  0.06803933  0.11388931\n",
      "  -0.8511742  -0.6840383  -0.3696006  -0.22373904  0.25922513 -0.90005916\n",
      "  -0.4516124   0.37639132  0.2970895   0.22256057 -0.5775304  -0.03633775\n",
      "   0.3135993  -0.5804622  -0.35701013 -0.7480397  -0.62862164  0.12727606\n",
      "  -0.45576513 -0.0414384   0.18847606 -0.11329078 -0.08643678  0.12724036\n",
      "   0.12335202 -0.22874287 -0.2991783   0.29896784  0.41772845  0.26217222\n",
      "  -0.38913837 -0.62962383 -0.5040003  -0.27541906 -0.129283   -0.29825008\n",
      "  -0.11595756 -0.3540829   0.0956834  -0.02775306  0.6940205  -0.09227671\n",
      "   0.15689558  0.3107318 ]\n",
      " [-0.14058846  0.23826517  0.4127439   0.19500181 -0.54425263 -0.15525483\n",
      "   0.84162056  0.20974219  0.2968884   0.11382529  0.6100584  -0.25685233\n",
      "   0.07832514 -0.01934533  0.07156423 -0.28291535  0.11772206  0.23008548\n",
      "   0.15107712 -0.23805672  0.22175711  0.35320473  0.21646932 -0.02474125\n",
      "  -0.64201725 -0.68680966  0.24974689 -0.63317734 -0.16911486 -0.03929098\n",
      "   0.06944899 -0.09594528  0.16301566 -0.04465562  0.45098537  0.36420777\n",
      "  -0.6375388  -0.43353707 -0.3948411  -0.18812144  0.23431575 -0.64158183\n",
      "  -0.4553715   0.1781156   0.4562718   0.18832177 -0.6224793   0.02623004\n",
      "   0.39224476 -0.3800481  -0.32013673 -0.67853314 -0.7339156   0.10565864\n",
      "  -0.2723072   0.03302608  0.16401818  0.05853877 -0.171272    0.13102807\n",
      "  -0.06568918 -0.29371762 -0.4153469   0.05311535  0.27453938  0.22733\n",
      "  -0.43423185 -0.37444228 -0.52201605 -0.30708253  0.06435482 -0.37939543\n",
      "  -0.15320379 -0.37644583 -0.236962    0.16498892  0.5387253  -0.06139998\n",
      "  -0.03246497  0.40693432]\n",
      " [-0.38409922 -0.004697    0.58277255  0.24188545 -0.6425295  -0.42941582\n",
      "   0.67375255  0.31350568  0.18691196  0.09768981  0.66901845 -0.22972612\n",
      "  -0.02055287 -0.14715958 -0.09295499 -0.3130335   0.41881293  0.16286069\n",
      "   0.13241065 -0.17423679  0.29178265  0.09876722  0.08583787 -0.22403066\n",
      "  -0.5131343  -0.82588613 -0.00594755 -0.55970716  0.08923867 -0.12048426\n",
      "   0.18582928 -0.02558712  0.22572067 -0.14915182  0.2187574   0.14786753\n",
      "  -0.90193653 -0.672527   -0.40635708 -0.21237361  0.27459815 -0.8074391\n",
      "  -0.4821201   0.33698896  0.3102039   0.25924924 -0.6235506   0.02962914\n",
      "   0.30740672 -0.5591577  -0.36960775 -0.7686396  -0.74931467  0.0110318\n",
      "  -0.44392216 -0.06525464  0.14976874 -0.10781754 -0.07885293  0.0692796\n",
      "   0.08834253 -0.19232765 -0.3341323   0.30773517  0.39073426  0.24717246\n",
      "  -0.44531775 -0.588522   -0.52061874 -0.3192011  -0.11093359 -0.3532616\n",
      "  -0.1826921  -0.4477309   0.00226457  0.0245986   0.6088537  -0.05893867\n",
      "   0.11143074  0.3098105 ]\n",
      " [-0.38798597  0.02564994  0.70919335  0.3107669  -0.64018774 -0.35538852\n",
      "   0.81950307  0.351758    0.15267478  0.15144825  0.6248974  -0.20705463\n",
      "  -0.13038418 -0.12163936 -0.18213516 -0.22855236  0.47673312  0.15177521\n",
      "   0.16598615 -0.1810947   0.2092826   0.13992967  0.0368157  -0.20822707\n",
      "  -0.43088934 -0.8171991   0.03076288 -0.526747    0.08558294 -0.05896622\n",
      "   0.12876192  0.01931494  0.23176596 -0.1503905   0.13668069  0.15954047\n",
      "  -0.8859391  -0.65505886 -0.36574996 -0.28518808  0.15749025 -0.8957467\n",
      "  -0.5370771   0.38740554  0.27868187  0.21466313 -0.5707701   0.07482547\n",
      "   0.19229662 -0.5541581  -0.3502269  -0.7750922  -0.6384995   0.06070729\n",
      "  -0.42537722 -0.04019539  0.1820682  -0.11595744 -0.08057731  0.14717275\n",
      "   0.08096617 -0.3076155  -0.36974913  0.24414062  0.40692234  0.25526085\n",
      "  -0.41867867 -0.5922078  -0.5282996  -0.23421796 -0.08815761 -0.29837847\n",
      "  -0.18156725 -0.4123945   0.04872598 -0.03481311  0.6863576  -0.02754398\n",
      "   0.11813536  0.40124524]\n",
      " [-0.39036712  0.06007484  0.5593312   0.14688641 -0.65263295 -0.5411977\n",
      "   0.574366    0.33015102  0.23486602  0.10670174  0.705386   -0.2827139\n",
      "  -0.14769349 -0.17232913 -0.18993175 -0.23990661  0.48176402  0.25498143\n",
      "   0.07097304 -0.20252785  0.24250326  0.1407946   0.03571743 -0.27031928\n",
      "  -0.42440116 -0.8312377   0.04608586 -0.51835096  0.08336017 -0.14258836\n",
      "   0.18789697 -0.01398838  0.33817756 -0.1585604   0.1748988   0.11731219\n",
      "  -0.8729059  -0.7946071  -0.49163073 -0.2533232   0.2598589  -0.8009248\n",
      "  -0.40212643  0.2424975   0.4407405   0.27786413 -0.56877196  0.02178364\n",
      "   0.38123363 -0.58741474 -0.3769996  -0.83332485 -0.7202083   0.04414653\n",
      "  -0.56447023 -0.15092774  0.16008726 -0.09686132 -0.16890508  0.14063814\n",
      "   0.15907492 -0.05977619 -0.2735783   0.48755747  0.42782903  0.32084304\n",
      "  -0.3346724  -0.69555414 -0.4955463  -0.39330307 -0.04483746 -0.3498962\n",
      "  -0.17460518 -0.4284771   0.12309912  0.07437356  0.58438885 -0.07966954\n",
      "   0.08845697  0.3316505 ]\n",
      " [-0.34625912 -0.00187039  0.6294455   0.2703109  -0.72825783 -0.5318523\n",
      "   0.6931524   0.37428588  0.09938715  0.15029472  0.7294992  -0.17661893\n",
      "  -0.07401168 -0.15970539 -0.21837822 -0.23749559  0.58829075  0.14299135\n",
      "   0.15201268 -0.13651377  0.24405618  0.10997394  0.11735991 -0.25248867\n",
      "  -0.4260165  -0.8894429  -0.06623514 -0.5328641   0.15283114 -0.20286684\n",
      "   0.18859847 -0.06336296  0.35970354 -0.18619247  0.17991412  0.03965234\n",
      "  -0.9473837  -0.8268545  -0.41604224 -0.26832885  0.3298421  -0.9340339\n",
      "  -0.4711648   0.35040054  0.30968726  0.27596062 -0.60482895 -0.00544953\n",
      "   0.32344806 -0.67296803 -0.3543448  -0.893318   -0.7563499   0.05324412\n",
      "  -0.58412564 -0.1430814   0.20461296 -0.12391528 -0.14118336  0.14626329\n",
      "   0.16937464 -0.08462614 -0.22198059  0.46619168  0.40201902  0.30085105\n",
      "  -0.37075612 -0.738641   -0.45401376 -0.23151076 -0.16072088 -0.29261547\n",
      "  -0.13784808 -0.42444912  0.1387258   0.011978    0.7280121  -0.05270352\n",
      "   0.18015122  0.2566182 ]]\n",
      "predictions: [76  6  6  6 10 10]\n",
      "translatedPredictions: ['Travel: Central & South America' 'Cozy Mysteries' 'Cozy Mysteries'\n",
      " 'Cozy Mysteries' 'U.S. History' 'U.S. History']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{model1.num_labels}\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "body = np.array([\"This wordless collection of strips by renowned artist/designer Rian Hughes reveals the lighter side of our obsession with social rankings.When everyone has a number, everyone knows their place. Lower numbers are better, higher numbers are less important, and that’s just the way it is. But what if that number could change? You might try to buck the system and assert your individuality… or you might end up with a big fat zero.Big questions are explored and unexpected answers found in the first solo comics collection from award-winning designer &amp; illustrator Rian Hughes. His whimsical, witty, and insightful strips will make you both smile and consider. Where do you stand in the pecking order? Is your number up? 2018 Pubwest Design Awards – Gold Winner for Graphic Album, New Material\",\n",
    "    \"There’s hot, and then there’s Delilah Devlin. She’s in a class  by herself.\",\n",
    "    \"A little girl proudly shows off her reading skills as she spends a day out on the town with her mom. Children are sure to be delighted as they read along with the narrator in ths fun, rhyming, easy-to-read story.\",\n",
    "    \"The Screech Owls have come to Salt Lake City for the Peewee Winter Games – with the championship game to be played on the same ice surface where the Canadian men and women won Olympic hockey gold! Nish has plans to run his own competition: the Gross-Out Olympics, featuring everything from taping players to dressing room walls with duct tape to the “Snot Shot” – seeing how far they can fire a jellybean using only their noses. He also has a team contest to see who can figure out the Great Nish Secret and guess what the nuttiest Screech Owl of all has buried at centre ice for good luck. But that secret pales once the Owls find out something strange – something terrifying – is going on in the tunnels deep beneath the magnificent hills surrounding the Olympic site.\",\n",
    "    \"Illus. in full color. Wild and domestic animals that preschoolers will want to see.From the Trade Paperback edition.\",            \n",
    "    \"With his unique knack for making cutting-edge theoretical science effortlessly accessible, world-renowned physicist Paul Davies now tackles an issue that has boggled minds for centuries: Is time travel possible? The answer, insists Davies, is definitely yes—once you iron out a few kinks in the space-time continuum. With tongue placed firmly in cheek, Davies explains the theoretical physics that make visiting the future and revisiting the past possible, then proceeds to lay out a four-stage process for assembling a time machine and making it work. Wildly inventive and theoretically sound, How to Build a Time Machine is creative science at its best—illuminating, entertaining, and thought provoking.\",\n",
    "])\n",
    "datapoints = pd.DataFrame()\n",
    "datapoints[\"body\"] = body\n",
    "\n",
    "predictions = model1.inference(datapoints, batch_size=16)\n",
    "translatedPredictions = model1.translatePredictions(predictions)\n",
    "\n",
    "print(f\"predictions: {predictions}\")\n",
    "print(f\"translatedPredictions: {translatedPredictions}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repository in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[80, 122, 109, 68, 45, 34, 19, 10, 2, 1, 1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "from HierarchicalBERT.BERTSentenceClassification import loadBSCmodel\n",
    "from BlurbDataset.BlurbDataset import BlurbDataset\n",
    "\n",
    "hierarchyLevel = 0 \n",
    "\n",
    "data = BlurbDataset(earlyStop=20, batch_size=16,\n",
    "                          tokenizedDataPath=\"BlurbDataset\")\n",
    "model = loadBSCmodel(\n",
    "    f\"BERTonBLURBHierarchyLevel{hierarchyLevel}.pt\", \n",
    "    num_labels = data.num_labels,\n",
    "    listLabelDict=data.listLabelDict,\n",
    "    hierarchyLevel=hierarchyLevel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization:   0%|          | 0/6 [00:00<?, ?it/s]c:\\Users\\luc.stebens\\Anaconda3\\envs\\BERTTextClassification\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Tokenization: 100%|██████████| 6/6 [00:00<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.37807125  0.25283247 -0.31736672  0.7352711  -0.53730255  0.21339744\n",
      "  -0.10350738  0.38484433  0.19312859 -0.34132108  0.12590154  0.27495706\n",
      "  -0.30296952 -0.30061874  0.05195042 -0.05847098  0.16094485  0.41501403\n",
      "  -0.20739505 -0.06255549 -0.42307395 -0.6746918  -0.54142404  0.12253863\n",
      "  -0.18547836 -0.19425286  0.23586583  0.6234082   0.09831981 -0.11390385\n",
      "   0.32362354  0.3338747   0.08734061 -0.0950475  -0.10994737  0.02449188\n",
      "   0.20407617 -0.21475616  0.11564394  0.03779422  0.28207052 -0.23779136\n",
      "  -0.08582821 -0.4682169  -0.08509855 -0.24818368  0.16808303 -0.07983072\n",
      "   0.32888848 -0.22858624  0.24297023  0.55142736  0.09568608  0.46457928\n",
      "   0.16842005  0.06575678 -0.20254448  0.01116027  0.13565129  0.3164239\n",
      "   0.07975817 -0.2945763   0.19667242 -0.18719773  0.05748653  0.21785654\n",
      "  -0.34548765 -0.3292947  -0.71230674 -0.31743833 -0.40765935  0.15825473\n",
      "  -0.04685668 -0.10344033  0.44210145  0.44645688 -0.2575978   0.06764287\n",
      "   0.5603034   0.38677764]\n",
      " [ 0.2686199  -0.14616294 -0.36669022  0.46699175 -0.49510765  0.39268234\n",
      "  -0.04321051  0.16767116  0.0852095  -0.17192984  0.04491337  0.07225639\n",
      "  -0.55020064 -0.5115856   0.26759946  0.06208435  0.06570219  0.47995758\n",
      "  -0.0047442  -0.19748376 -0.22431724 -0.64246213  0.07875273 -0.05164409\n",
      "   0.09886563 -0.09490913  0.13758114  0.38657486  0.0710737   0.14010574\n",
      "   0.09480365 -0.0815557  -0.0692495  -0.29437244  0.01627743  0.21444595\n",
      "   0.06633776  0.05584875  0.29444382 -0.25154188  0.38450027  0.14089656\n",
      "  -0.25241548 -0.4660812  -0.03727368 -0.34252217  0.12661979 -0.1366083\n",
      "   0.48266098 -0.3494398   0.44036472  0.26712966 -0.01066651  0.3531947\n",
      "   0.45303437  0.1653722  -0.08796431 -0.01803785  0.18459728  0.45656556\n",
      "   0.18832332 -0.5343081  -0.16214563 -0.12995885 -0.03384095 -0.23543084\n",
      "  -0.41942158 -0.21049169 -0.32315335 -0.34703454 -0.38757864 -0.06700805\n",
      "   0.14033915 -0.02765866  0.5442641   0.78857887 -0.23324963  0.26071137\n",
      "   0.46781665  0.00795679]\n",
      " [ 0.38561434  0.24024755 -0.3036717   0.76429635 -0.47584093  0.25889724\n",
      "  -0.29226607  0.32671884  0.2055541  -0.29242563  0.08509458  0.2219811\n",
      "  -0.3790381  -0.21114983  0.09227261  0.06669002  0.15708005  0.47321865\n",
      "  -0.2561712  -0.19254653 -0.36777708 -0.65255576 -0.596229    0.0397266\n",
      "  -0.08327861 -0.12022356  0.2831568   0.536158    0.14401142 -0.16362274\n",
      "   0.3034931   0.3563197   0.24574825 -0.13012782  0.05161467  0.06465521\n",
      "   0.20812581 -0.11874921  0.20597847 -0.03579994  0.36794835 -0.2532397\n",
      "  -0.13796744 -0.5512409   0.02973792 -0.21685825  0.15395664 -0.05811107\n",
      "   0.45906767 -0.29502708  0.23802     0.5712107  -0.1483998   0.6899812\n",
      "   0.44559467  0.05255346 -0.12315357  0.11585807  0.3053995   0.44177622\n",
      "   0.02862056 -0.19249743  0.12700921 -0.26158983 -0.00365934  0.4402659\n",
      "  -0.35269058 -0.35600019 -0.70921135 -0.3916809  -0.39042094  0.28165358\n",
      "   0.08193678 -0.02415811  0.45775113  0.5061743  -0.3414245   0.00839256\n",
      "   0.5832542   0.41419414]\n",
      " [ 0.38232368  0.28563643 -0.22589263  0.7018955  -0.5704644   0.26556942\n",
      "  -0.13068868  0.3708774   0.05745105 -0.42571783  0.2668395   0.29437044\n",
      "  -0.3730218  -0.28061002  0.13493402  0.00512     0.11863407  0.359398\n",
      "  -0.09531984  0.05097684 -0.36411583 -0.755919   -0.539667    0.12256806\n",
      "  -0.14943561 -0.19509415  0.19474244  0.61938167  0.303068   -0.18436061\n",
      "   0.3342468   0.18141752  0.02782725 -0.20354357 -0.11424085 -0.06205791\n",
      "   0.14523628 -0.12014643  0.20275216 -0.08969421  0.17695653 -0.24300563\n",
      "  -0.10559718 -0.5751751  -0.08402891 -0.1731498   0.2019439  -0.05720657\n",
      "   0.35152087 -0.18653595  0.22954245  0.49721003  0.19010645  0.29991412\n",
      "   0.11739382  0.11904708 -0.2318328  -0.00406349  0.18331923  0.3320146\n",
      "   0.13007751 -0.428836    0.08645376 -0.14273065  0.05723351  0.11581309\n",
      "  -0.25232118 -0.18851422 -0.7634653  -0.28557515 -0.454618    0.0495761\n",
      "   0.06124871  0.00941315  0.5680691   0.524863   -0.15741742  0.02149218\n",
      "   0.4060682   0.23835966]\n",
      " [ 0.49065778  0.21231195 -0.39301753  0.68102837 -0.45420688  0.2943533\n",
      "  -0.29470098  0.36820114  0.1875521  -0.34395775  0.11580506  0.36631927\n",
      "  -0.32084754 -0.16053757  0.12211862  0.05437243  0.22927085  0.2577223\n",
      "  -0.42447546 -0.17944069 -0.42289108 -0.6813986  -0.59508705  0.2547657\n",
      "  -0.2386061  -0.10256575  0.2925499   0.6732776   0.22323194 -0.15218726\n",
      "   0.31977433  0.44468242  0.26159427 -0.07919112  0.0891632   0.15419722\n",
      "   0.2968244  -0.15069675  0.4351148   0.13818371  0.42323172 -0.16008106\n",
      "  -0.3761087  -0.36732218 -0.08052437 -0.26464304  0.13827953 -0.20764974\n",
      "   0.55700046 -0.25762025  0.2771451   0.63885087 -0.27024043  0.784413\n",
      "   0.3346152   0.06124004 -0.06129637  0.23172855  0.29540324  0.46180755\n",
      "  -0.05334422 -0.00618222  0.1868327  -0.12758161 -0.00158113  0.68167025\n",
      "  -0.58853394 -0.51343656 -1.0021981  -0.57923967 -0.4875754   0.19222583\n",
      "  -0.14372377 -0.0386028   0.5227843   0.29774562 -0.3121026   0.13922375\n",
      "   0.512705    0.5100487 ]\n",
      " [ 0.34395054  0.40634865 -0.29627776  0.7740167  -0.52578735  0.3760488\n",
      "  -0.16559805  0.4516602   0.10995624 -0.47051477  0.18250075  0.31963834\n",
      "  -0.20819145 -0.27285638  0.08747081 -0.05968294  0.09664609  0.27053332\n",
      "  -0.31903568  0.01264912 -0.49039912 -0.7591529  -0.7174517   0.22106132\n",
      "  -0.23962398 -0.11886959  0.37354493  0.7215692   0.30143034 -0.27073932\n",
      "   0.33382556  0.40066236  0.13708916 -0.1289106  -0.04820475 -0.03538194\n",
      "   0.27971104 -0.21058266  0.2764803   0.0112485   0.17750177 -0.2548599\n",
      "  -0.30960375 -0.48101228 -0.11481367 -0.12296556  0.07599838 -0.0869939\n",
      "   0.43413812 -0.19432482  0.24856623  0.66891646  0.05278984  0.48949203\n",
      "   0.1505947   0.06596067 -0.23469675  0.11709375  0.2950166   0.31888998\n",
      "  -0.01550773 -0.23721477  0.29085383 -0.15057838  0.05126323  0.34173825\n",
      "  -0.37156683 -0.35078263 -1.1914604  -0.36322606 -0.48491493  0.17857276\n",
      "  -0.16260791  0.02706751  0.55845076  0.47181097 -0.05791226  0.21644631\n",
      "   0.51763636  0.44929653]]\n",
      "predictions: [ 3 75  3  3 53  3]\n",
      "translatedPredictions: ['Teen & Young Adult' 'Travel: Australia & Oceania' 'Teen & Young Adult'\n",
      " 'Teen & Young Adult' 'New Adult Romance' 'Teen & Young Adult']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "body = np.array([\"This wordless collection of strips by renowned artist/designer Rian Hughes reveals the lighter side of our obsession with social rankings.When everyone has a number, everyone knows their place. Lower numbers are better, higher numbers are less important, and that’s just the way it is. But what if that number could change? You might try to buck the system and assert your individuality… or you might end up with a big fat zero.Big questions are explored and unexpected answers found in the first solo comics collection from award-winning designer &amp; illustrator Rian Hughes. His whimsical, witty, and insightful strips will make you both smile and consider. Where do you stand in the pecking order? Is your number up? 2018 Pubwest Design Awards – Gold Winner for Graphic Album, New Material\",\n",
    "    \"There’s hot, and then there’s Delilah Devlin. She’s in a class  by herself.\",\n",
    "    \"A little girl proudly shows off her reading skills as she spends a day out on the town with her mom. Children are sure to be delighted as they read along with the narrator in ths fun, rhyming, easy-to-read story.\",\n",
    "    \"The Screech Owls have come to Salt Lake City for the Peewee Winter Games – with the championship game to be played on the same ice surface where the Canadian men and women won Olympic hockey gold! Nish has plans to run his own competition: the Gross-Out Olympics, featuring everything from taping players to dressing room walls with duct tape to the “Snot Shot” – seeing how far they can fire a jellybean using only their noses. He also has a team contest to see who can figure out the Great Nish Secret and guess what the nuttiest Screech Owl of all has buried at centre ice for good luck. But that secret pales once the Owls find out something strange – something terrifying – is going on in the tunnels deep beneath the magnificent hills surrounding the Olympic site.\",\n",
    "    \"Illus. in full color. Wild and domestic animals that preschoolers will want to see.From the Trade Paperback edition.\",            \n",
    "    \"With his unique knack for making cutting-edge theoretical science effortlessly accessible, world-renowned physicist Paul Davies now tackles an issue that has boggled minds for centuries: Is time travel possible? The answer, insists Davies, is definitely yes—once you iron out a few kinks in the space-time continuum. With tongue placed firmly in cheek, Davies explains the theoretical physics that make visiting the future and revisiting the past possible, then proceeds to lay out a four-stage process for assembling a time machine and making it work. Wildly inventive and theoretically sound, How to Build a Time Machine is creative science at its best—illuminating, entertaining, and thought provoking.\",\n",
    "])\n",
    "datapoints = pd.DataFrame()\n",
    "datapoints[\"body\"] = body\n",
    "\n",
    "predictions = model.inference(datapoints, batch_size=16)\n",
    "translatedPredictions = model.translatePredictions(predictions)\n",
    "\n",
    "print(f\"predictions: {predictions}\")\n",
    "print(f\"translatedPredictions: {translatedPredictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization:   0%|          | 0/6 [00:00<?, ?it/s]c:\\Users\\luc.stebens\\Anaconda3\\envs\\BERTTextClassification\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Tokenization: 100%|██████████| 6/6 [00:00<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01930444 -0.01977405 -0.04699296 -0.06746225 -0.11384522 -0.20708346\n",
      "  -0.09043156 -0.23449738  0.1836006   0.68727237  0.5843393 ]\n",
      " [ 0.18506268  0.11881091  0.08708183  0.16918835 -0.24148497 -0.17198133\n",
      "  -0.1761727  -0.20034899  0.28422558  0.5798515   0.57429403]\n",
      " [ 0.09212276  0.0359113  -0.05348908  0.03614424 -0.1359228  -0.14843228\n",
      "  -0.109568   -0.2002545   0.22960085  0.69252837  0.6429902 ]\n",
      " [ 0.00398067 -0.02537885 -0.01953503  0.01560123 -0.08067893 -0.23796493\n",
      "  -0.13083985 -0.2020143   0.08343008  0.72332877  0.66916794]\n",
      " [ 0.11997294  0.04849662 -0.06645413 -0.08903764  0.03563287 -0.16460341\n",
      "  -0.09303817 -0.27455327  0.18189725  0.7047241   0.7239775 ]\n",
      " [ 0.03795041  0.02273951 -0.08966117  0.03516039 -0.02574408 -0.17068802\n",
      "  -0.10287824 -0.1952268   0.24558523  0.68173003  0.7122874 ]]\n",
      "predictions: [ 9  9  9  9 10 10]\n",
      "translatedPredictions: ['Religion' 'Religion' 'Religion' 'Religion' 'U.S. History' 'U.S. History']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "body = np.array([\"This wordless collection of strips by renowned artist/designer Rian Hughes reveals the lighter side of our obsession with social rankings.When everyone has a number, everyone knows their place. Lower numbers are better, higher numbers are less important, and that’s just the way it is. But what if that number could change? You might try to buck the system and assert your individuality… or you might end up with a big fat zero.Big questions are explored and unexpected answers found in the first solo comics collection from award-winning designer &amp; illustrator Rian Hughes. His whimsical, witty, and insightful strips will make you both smile and consider. Where do you stand in the pecking order? Is your number up? 2018 Pubwest Design Awards – Gold Winner for Graphic Album, New Material\",\n",
    "    \"There’s hot, and then there’s Delilah Devlin. She’s in a class  by herself.\",\n",
    "    \"A little girl proudly shows off her reading skills as she spends a day out on the town with her mom. Children are sure to be delighted as they read along with the narrator in ths fun, rhyming, easy-to-read story.\",\n",
    "    \"The Screech Owls have come to Salt Lake City for the Peewee Winter Games – with the championship game to be played on the same ice surface where the Canadian men and women won Olympic hockey gold! Nish has plans to run his own competition: the Gross-Out Olympics, featuring everything from taping players to dressing room walls with duct tape to the “Snot Shot” – seeing how far they can fire a jellybean using only their noses. He also has a team contest to see who can figure out the Great Nish Secret and guess what the nuttiest Screech Owl of all has buried at centre ice for good luck. But that secret pales once the Owls find out something strange – something terrifying – is going on in the tunnels deep beneath the magnificent hills surrounding the Olympic site.\",\n",
    "    \"Illus. in full color. Wild and domestic animals that preschoolers will want to see.From the Trade Paperback edition.\",            \n",
    "    \"With his unique knack for making cutting-edge theoretical science effortlessly accessible, world-renowned physicist Paul Davies now tackles an issue that has boggled minds for centuries: Is time travel possible? The answer, insists Davies, is definitely yes—once you iron out a few kinks in the space-time continuum. With tongue placed firmly in cheek, Davies explains the theoretical physics that make visiting the future and revisiting the past possible, then proceeds to lay out a four-stage process for assembling a time machine and making it work. Wildly inventive and theoretically sound, How to Build a Time Machine is creative science at its best—illuminating, entertaining, and thought provoking.\",\n",
    "])\n",
    "datapoints = pd.DataFrame()\n",
    "datapoints[\"body\"] = body\n",
    "\n",
    "predictions = model1.inference(datapoints, batch_size=16)\n",
    "translatedPredictions = model1.translatePredictions(predictions)\n",
    "\n",
    "print(f\"predictions: {predictions}\")\n",
    "print(f\"translatedPredictions: {translatedPredictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Check that the model saving and loading wokrs i.e. the loaded model is the same one as the safed one. -> Forgot to remove a line from BSC constructor. Seems to work now!\n",
    "2) Check trainBERT.py file\n",
    "3) Check tokenized saved files\n",
    "4) Actually train and see if current architecture is working fine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERTTextClassification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
